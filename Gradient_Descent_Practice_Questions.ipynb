{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JFJ4kNvhISjM",
        "outputId": "1ed634b7-09f8-4bb2-ab9e-385fd881d841"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "|   Iteration | theta                   |         J | Partial derivatives         |\n",
            "|-------------|-------------------------|-----------|-----------------------------|\n",
            "|           1 | [0. 0.]                 | 32.3333   | [ -8.         -40.66666667] |\n",
            "|           2 | [0.4        2.03333333] |  3.64981  | [ 2.56666667 13.52222222]   |\n",
            "|           3 | [0.27166667 1.35722222] |  0.486427 | [-0.94222222 -4.47296296]   |\n",
            "|           4 | [0.31877778 1.58087037] |  0.137364 | [0.22312963 1.50289506]     |\n"
          ]
        }
      ],
      "source": [
        "from tabulate import tabulate\n",
        "import numpy as np\n",
        "\n",
        "def gradient_descent(X, y, alpha, num_iters):\n",
        "    m = y.size  # number of training examples\n",
        "    theta = np.zeros(2)  # initialize parameters to zero\n",
        "    data = []  # keep track of cost function values\n",
        "    for i in range(num_iters):\n",
        "        # Calculate hypothesis and cost function\n",
        "        h = X.dot(theta)\n",
        "        J = np.sum((h - y) ** 2) / (2 * m)\n",
        "        partial_derivatives = X.T.dot(h - y) / m\n",
        "        data.append([i+1, np.copy(theta), J, partial_derivatives])\n",
        "        #update parameters\n",
        "        theta -= alpha / m * (X.T.dot(h - y))\n",
        "       \n",
        "        # Print table of parameter values and partial derivatives of J\n",
        "    print(tabulate(data, headers=['Iteration', 'theta', 'J', 'Partial derivatives'], tablefmt='github'))\n",
        "        \n",
        "    return \n",
        "\n",
        "# Generate some example data points\n",
        "x = np.array([4, 5, 6])\n",
        "y = np.array([7, 8, 9])\n",
        "\n",
        "# Add a column of ones for the intercept term\n",
        "X = np.vstack((np.ones(x.size), x)).T\n",
        "\n",
        "# Set the learning rate and number of iterations\n",
        "alpha = 0.05\n",
        "gradient_descent(X, y, alpha, num_iters=4)\n"
      ]
    }
  ]
}